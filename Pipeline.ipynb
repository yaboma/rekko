{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yabom\\Anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import implicit\n",
    "import lightfm\n",
    "import warnings\n",
    "from validation_prepare import *\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recomend(model,X,fe,test_users,user_history_films,user_features = None,item_features = None,mode = 'lightfm',N = 20,is_filter_history = True):\n",
    "    # Сделаем какой-нибудь сабмит из lightfm\n",
    "    result = {}\n",
    "    #'implicit'#'lightfm'\n",
    "    cnt = 0\n",
    "    for user_uid in tqdm.tqdm(test_users):\n",
    "\n",
    "        # transform user_uid to model's internal user category\n",
    "        try:\n",
    "            user_cat = fe.match_user_row[user_uid]\n",
    "        except LookupError:\n",
    "            continue\n",
    "        \n",
    "        if mode == 'lightfm':\n",
    "            if is_filter_history:\n",
    "                need_cols = np.array(list(set(np.arange(X.shape[1])) - user_history_films.get(user_cat, set())))\n",
    "            else:\n",
    "                need_cols = np.array(list(set(np.arange(X.shape[1]))))\n",
    "            recs = model.predict(user_cat,need_cols,item_features=item_features,user_features=user_features)\n",
    "            need_movies = np.argsort(-recs)[:N]\n",
    "            result[user_uid] = [int(fe.train_movie_match_row_movie[i]) for i in need_movies]\n",
    "            \n",
    "                \n",
    "        # переводим в фильмы\n",
    "\n",
    "        # perform inference\n",
    "        if mode == 'implicit':\n",
    "            if cnt == 0:\n",
    "                ratings_matrix_T = X.tocsr()\n",
    "            if is_filter_history:\n",
    "                recs = model.recommend(\n",
    "                    user_cat,\n",
    "                    X.tocsr(),\n",
    "                    N=N,\n",
    "                    filter_already_liked_items=True,\n",
    "                    filter_items=user_history_films.get(user_uid, set())\n",
    "                )\n",
    "            else:\n",
    "                recs = model.recommend(\n",
    "                    user_cat,\n",
    "                    X.tocsr(),\n",
    "                    N=N,filter_already_liked_items=False,\n",
    "                )\n",
    "            result[user_uid] = [int(fe.train_movie_match_row_movie[i]) for i, _ in recs]\n",
    "            # drop scores and transform model's internal elelemnt category to element_uid for every prediction\n",
    "        # also convert np.uint64 to int so it could be json serialized later\n",
    "        cnt += 1\n",
    "    return result\n",
    "\n",
    "def get_predict (model,X,fe,test_users,user_history_films,user_features = None,item_features = None,mode = 'lightfm',):\n",
    "    # Сделаем какой-нибудь сабмит из lightfm\n",
    "    result = {}\n",
    "    #'implicit'#'lightfm'\n",
    "    cnt = 0\n",
    "    for user_uid in tqdm.tqdm(test_users):\n",
    "\n",
    "        # transform user_uid to model's internal user category\n",
    "        try:\n",
    "            user_cat = fe.match_user_row[user_uid]\n",
    "        except LookupError:\n",
    "            continue\n",
    "        \n",
    "        if mode == 'lightfm':\n",
    "#             if is_filter_history:\n",
    "#                 need_cols = np.array(list(set(np.arange(X.shape[1])) - user_history_films.get(user_cat, set())))\n",
    "#             else:\n",
    "            need_cols = np.array(list(set(np.arange(X.shape[1]))))\n",
    "            recs = model.predict(user_cat,need_cols,item_features=item_features,user_features=user_features)\n",
    "            #need_movies = np.argsort(-recs)[:N]\n",
    "            result[user_uid] = recs#[int(fe.train_movie_match_row_movie[i]) for i in need_movies]\n",
    "            \n",
    "                \n",
    "        # переводим в фильмы\n",
    "\n",
    "        # perform inference\n",
    "        if mode == 'implicit':\n",
    "            if cnt == 0:\n",
    "                ratings_matrix_T = X.tocsr()\n",
    "            \n",
    "            recs = model.rank_items(user_cat, X.tocsr(), np.arange(X.shape[1]), )\n",
    "            recs = sorted(recs,key = lambda x:x[0])\n",
    "            \n",
    "            result[user_uid] = [score for i, score in recs]\n",
    "            # drop scores and transform model's internal elelemnt category to element_uid for every prediction\n",
    "        # also convert np.uint64 to int so it could be json serialized later\n",
    "            cnt += 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',100)\n",
    "\n",
    "DATA_PATH = '../okko/orig_data'\n",
    "PREPARED_PATH = './prepared_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = pd.read_pickle(PREPARED_PATH+'actions_one_table.pkl')\n",
    "\n",
    "actions.sort_index(inplace = True) # На всякий случай, иначе деление не будет работать\n",
    "\n",
    "actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,_,watch_actions,_ = get_target(actions)\n",
    "\n",
    "actions = actions.join(watch_actions['rel_dur'])\n",
    "\n",
    "actions['rel_dur'] = actions['rel_dur'].fillna(0).replace(np.inf,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = get_train_test(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.iloc[idx[0]].index.get_level_values(2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.iloc[idx[1]].index.get_level_values(2).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.iloc[idx[1]].index.get_level_values(2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.iloc[idx[2]].index.get_level_values(2).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.consumption_mode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'test_users.json'), 'r') as f:\n",
    "    test_users = set(json.load(f)['users'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вроде не пересекается.\n",
    "train,test,valid = actions.iloc[idx[0]],actions.iloc[idx[1]],actions.iloc[idx[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time \n",
    "dur_being_train,dur_films_train,watch_actions_train,target_train = get_target(train)\n",
    "dur_being_test,dur_films_test,watch_actions_test,target_test = get_target(test)\n",
    "dur_being_valid,dur_films_valid,watch_actions_valid,target_valid = get_target(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получили фичи для фильмов\n",
    "import pickle\n",
    "with open(PREPARED_PATH+'catalogue_features.pkl','rb') as f:\n",
    "    match_element_row,match_row_element,match_columns,element_matrix = pickle.load(f)\n",
    "movie_match_columns = {i:ii for ii,i in enumerate(match_columns)}\n",
    "movie_columns_match = {ii:i for ii,i in enumerate(match_columns)}\n",
    "\n",
    "with open(PREPARED_PATH+'bag_of_attr_movie.pkl','rb') as f:\n",
    "    bag_of_attr = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureExtractor({'movie_attr_matrix':element_matrix,'movie_match_columns':movie_match_columns,\n",
    "                       'movie_columns_match':movie_columns_match,'movie_match_row_movie':match_row_element,\n",
    "                      'movie_match_movie_row':match_element_row,},bag_of_attr,is_censor = True,delimiter=-1,mode = 'duration',\n",
    "                     target_col_name='rel_dur')\n",
    "\n",
    "fe = FeatureExtractor({'movie_attr_matrix':element_matrix,'movie_match_columns':movie_match_columns,\n",
    "                       'movie_columns_match':movie_columns_match,'movie_match_row_movie':match_row_element,\n",
    "                      'movie_match_movie_row':match_element_row,},bag_of_attr,is_censor =False,delimiter=4,)\n",
    "\n",
    "fe.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = fe.transform(train)\n",
    "test_ = fe.transform(test)\n",
    "valid_ = fe.transform(valid)\n",
    "\n",
    "train_.shape,test_.shape \n",
    "\n",
    "cfe = ColdFeatureExtractor(fe)\n",
    "\n",
    "cfe.fit(train)\n",
    "\n",
    "max(cfe.train_movie_cols)\n",
    "\n",
    "# sp.csc_matrix(cfe.fitted_FE.movie_attr_matrix)[cfe.train_movie_rows,cfe.train_movie_cols]\n",
    "\n",
    "\n",
    "\n",
    "train_res = cfe.transform(test)\n",
    "\n",
    "\n",
    "print(train_res['train_user'].shape,train_res['test_user'].shape,train_res['new_test_user'].shape)\n",
    "\n",
    "print(train_res['train_movie'].shape,train_res['test_movie'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Здесь начинается русское поле экспериментов над параметрами моделей.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_.shape,test_.shape,valid_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res['train_movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "a,b = train_.nonzero()\n",
    "D_row_col_train = defaultdict(set)\n",
    "D_user_movie_train = defaultdict(set)\n",
    "for i,ii in tqdm.tqdm(zip(a,b),total = len(a)):\n",
    "    D_row_col_train[i].add(ii)\n",
    "    D_user_movie_train[fe.match_row_user[i]].add(fe.train_movie_match_row_movie[ii])\n",
    "\n",
    "from collections import defaultdict\n",
    "a,b = test_.nonzero()\n",
    "D_row_col_test = defaultdict(set)\n",
    "D_user_movie_test = defaultdict(set)\n",
    "for i,ii in tqdm.tqdm(zip(a,b),total = len(a)):\n",
    "    D_row_col_test[i].add(ii)\n",
    "    D_user_movie_test[fe.match_row_user[i]].add(fe.train_movie_match_row_movie[ii])\n",
    "\n",
    "from collections import defaultdict\n",
    "a,b = valid_.nonzero()\n",
    "D_row_col_valid = defaultdict(set)\n",
    "D_user_movie_valid = defaultdict(set)\n",
    "for i,ii in tqdm.tqdm(zip(a,b),total = len(a)):\n",
    "    D_row_col_valid[i].add(ii)\n",
    "    D_user_movie_valid[fe.match_row_user[i]].add(fe.train_movie_match_row_movie[ii])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = 0\n",
    "epochs = 30\n",
    "num_threads=4\n",
    "\n",
    "model = lightfm.LightFM(loss = 'warp',random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours import TFIDFRecommender,CosineRecommender,NearestNeighboursScorer,BM25Recommender,bm25_weight\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.evaluation import mean_average_precision_at_k,precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import precision_at_k,auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_im = BM25Recommender()#CosineRecommender()\n",
    "model_im.fit(train_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recs_model_im_test = get_predict(model_im,train_,fe,D_user_movie_test.keys(),D_row_col_train,mode = 'implicit')\n",
    "\n",
    "# list(recs_model_im_test.keys())[0]\n",
    "\n",
    "# len(recs_model_im_test[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lightfm.LightFM(loss = 'logistic',random_state=seed,max_sampled=100,no_components=100)\n",
    "model.fit(train_,epochs=30,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Здесь простецкий стекинг делать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_model_test = get_predict(model,train_,fe,D_user_movie_test.keys(),D_row_col_train,mode = 'lightfm')\n",
    "len(recs_model_test[list(recs_model_test.keys())[0]])\n",
    "len(recs_model_test[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_model_valid = get_predict(model,train_,fe,D_user_movie_valid.keys(),D_row_col_train,mode = 'lightfm')\n",
    "len(recs_model_valid[list(recs_model_valid.keys())[0]])\n",
    "#len(recs_model_valid[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs_model_test_true = get_predict(model,train_,fe,test_users,D_row_col_train,mode = 'lightfm')\n",
    "len(recs_model_test_true[list(recs_model_test_true.keys())[0]]),len(recs_model_test_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'catalogue.json'), 'r') as f:\n",
    "    catalogue = json.load(f)\n",
    "    \n",
    "catalogue = {int(k): v for k, v in catalogue.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_attr = set()\n",
    "for i,ii in catalogue.items():\n",
    "    s_attr.update(set(ii['attributes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_attr = list(s_attr)\n",
    "s_attr = sorted(s_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_dict_attr = {i:ii for ii,i in enumerate(s_attr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_feat(movie_id,data_catalogue_orig,shift = 0):\n",
    "    l = catalogue[movie_id]['attributes']\n",
    "    return {(s_dict_attr[i]+shift):1 for i in l}\n",
    "def convert_to_range(X,data_catalogue_orig,path = PREPARED_PATH+'train.txt', label_name = 'target',need_feat = None):\n",
    "    '''\n",
    "    конвертируем в libsvm вместе с query файлом\n",
    "    '''\n",
    "    # Сначала рейтинг 0...10\n",
    "    buf_tr = []\n",
    "    buf_query = []\n",
    "    cnt = 0\n",
    "    for i in tqdm.tqdm(np.unique(X.index.get_level_values(0))):\n",
    "        cnt_film = 0\n",
    "        temp = X.loc[i]\n",
    "        for movie_id in temp.index.get_level_values(0):\n",
    "            row = temp.loc[movie_id,need_feat].to_dict()\n",
    "            row = {need_feat.index(i):ii for i,ii in row.items()}\n",
    "            dict_row = get_movie_feat(movie_id,data_catalogue_orig,shift = len(row))\n",
    "            dict_row.update(row)\n",
    "            s_movie = str(int(temp.loc[movie_id,label_name]))+' '\n",
    "            dict_row = dict(sorted(dict_row.items()))\n",
    "            cnt+=1\n",
    "            for k,kk in dict_row.items():\n",
    "                s_movie+= str(k)+':'+str(kk)+' '\n",
    "            s_movie+='\\n'\n",
    "            buf_tr.append(s_movie)\n",
    "            cnt_film+=1\n",
    "            cnt+=1\n",
    "        buf_query.append(str(cnt_film)+'\\n')\n",
    "    with open(path,'w') as f:\n",
    "        for i in buf_tr:\n",
    "            f.write(i)\n",
    "    with open(path+'.query','w') as f:\n",
    "        for i in buf_query:\n",
    "            f.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = pd.read_pickle(PREPARED_PATH+'some_wm.pkl')\n",
    "wm_cut = wm.loc[~wm.rating.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !help('modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# reload('validation_prepare.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_wm = get_train_test(wm,mode = 'by_time_wm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test,valid = wm.iloc[idx_wm[0]],wm.iloc[idx_wm[1]],wm.iloc[idx_wm[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.first_ts.max(),test.first_ts.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пока оставим только тру рейтинги\n",
    "train,test,valid = train.dropna(subset = ['rating']),test.dropna(subset = ['rating']),valid.dropna(subset = ['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_feat =['rel_dur','diff_ts','duration','feature_1','feature_2','feature_3','feature_4','feature_5','num_watched_user'\n",
    "            ,'probably_kp_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not os.path.exists(PREPARED_PATH+'train.txt'):\n",
    "convert_to_range(train,catalogue,label_name = 'rating',need_feat = need_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not os.path.exists(PREPARED_PATH+'test.txt'):\n",
    "convert_to_range(test,catalogue,label_name = 'rating',need_feat = need_feat,path = PREPARED_PATH+'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = load_svmlight_file(PREPARED_PATH+'test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PREPARED_PATH+'train.txt.query') as f:\n",
    "    q_train = []\n",
    "    for i in f:\n",
    "        q_train.append(int(i.replace('\\n','')))\n",
    "with open(PREPARED_PATH+'test.txt.query') as f:\n",
    "    q_test = []\n",
    "    for i in f:\n",
    "        q_test.append(int(i.replace('\\n','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lightgbm.Dataset(PREPARED_PATH+'train.txt',group = q_train)\n",
    "lgb_test = lightgbm.Dataset(PREPARED_PATH+'test.txt',group = q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_feat[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective':'lambdarank',\n",
    "#     'data': PREPARED_PATH+'train.txt',\n",
    "#     'valid':PREPARED_PATH+'test.txt',\n",
    "#     'metric':'map',\n",
    "}\n",
    "model = lightgbm.train(params,lgb_train,valid_sets=lgb_test,verbose_eval=True,num_boost_round=1000,early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(x)\n",
    "p#.reshape((-1,11)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (10,20))\n",
    "lightgbm.plot_importance(model,ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_recomend(model_im,train_,fe,D_user_movie_train.keys(),D_row_col_train,mode = 'implicit',is_filter_history=False)\n",
    "\n",
    "metric(D_user_movie_train,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_recomend(model_im,train_,fe,D_user_movie_test.keys(),D_row_col_train,mode = 'implicit')\n",
    "\n",
    "metric(D_user_movie_test,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_recomend(model_im,train_,fe,D_user_movie_valid.keys(),D_row_col_train,mode = 'implicit')\n",
    "\n",
    "metric(D_user_movie_valid,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision_at_k(model,train_,test_,k = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Организуем hyperopt\n",
    "import colorama\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "\n",
    "\n",
    "space ={\n",
    "        'loss': hp.choice( 'loss', ['logistic', 'warp' ] ),\n",
    "        'learning_schedule': hp.choice(\"learning_schedule\", ['adagrad','adadelta']),\n",
    "        'rho':  hp.quniform('rho', 0.75, 0.99,0.05),\n",
    "        'max_sampled': hp.quniform('max_sampled', 10, 1000,20),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -6.9, -1),  \n",
    "        'no_components':hp.quniform('no_components',5,200,5),\n",
    "       }\n",
    "cur_best_loss = np.inf\n",
    "cnt = 1\n",
    "\n",
    "\n",
    "def get_params(space):\n",
    "    px = dict()\n",
    "    px['loss'] = space['loss']\n",
    "    px['learning_schedule'] = space['learning_schedule']\n",
    "    px['rho'] = min(0.99,space['rho'])\n",
    "    px['max_sampled'] = int(space['max_sampled'])\n",
    "    px['learning_rate'] = space['learning_rate']\n",
    "    px['no_components'] = int(space['no_components'])\n",
    "    \n",
    "    return px\n",
    "def objective(space):\n",
    "    global cur_best_loss,cnt\n",
    "    params = get_params(space)\n",
    "    model = lightfm.LightFM(random_state=seed,**params,)\n",
    "    model.fit(train_,epochs=30,)\n",
    "    res = get_recomend(model,train_,fe,D_user_movie_test.keys(),D_row_col_train)\n",
    "    #score = custom_mae(l.values,p.values)\n",
    "    score = -metric(D_user_movie_test,res)\n",
    "    if cnt%10 == 0:\n",
    "        print('Попытка номер:',cnt)\n",
    "    if score < cur_best_loss:\n",
    "        cur_best_loss = score\n",
    "        print(colorama.Fore.GREEN + 'NEW BEST LOSS={}'.format(-cur_best_loss) + colorama.Fore.RESET)\n",
    "        print(params)\n",
    "    cnt+=1\n",
    "    return {'loss':score, 'status': STATUS_OK }\n",
    "trials = Trials()\n",
    "# best = hyperopt.fmin(fn=objective,\n",
    "#                      space=space,\n",
    "#                      algo=tpe.suggest,\n",
    "#                      max_evals=200,\n",
    "#                      trials=trials,\n",
    "#                      verbose=2)\n",
    "p={'loss': 'warp', 'learning_schedule': 'adagrad', 'rho': 0.75, 'max_sampled': 460, 'learning_rate': 0.005108939164793534, 'no_components': 160}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_recomend(model,train_,fe,D_user_movie_test.keys(),D_row_col_train)#test_users#,mode = 'implicit'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric(D_user_movie_test,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Валидация\n",
    "res = get_recomend(model,valid_,fe,D_user_movie_valid.keys(),D_row_col_train)#,mode = 'implicit'\n",
    "metric(D_user_movie_valid,res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(D_user_movie_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(D_user_movie_test.keys()) & set(res.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Здесь заканчиваетс/ русское поле экспериментов\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm = pd.read_pickle(PREPARED_PATH+'some_wm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим, что не загибается на полном датасете\n",
    "\n",
    "fe = FeatureExtractor({'movie_attr_matrix':element_matrix,'movie_match_columns':movie_match_columns,\n",
    "                       'movie_columns_match':movie_columns_match,'movie_match_row_movie':match_row_element,\n",
    "                      'movie_match_movie_row':match_element_row,},bag_of_attr,is_censor = True,delimiter=4,)\n",
    "\n",
    "\n",
    "# fe = FeatureExtractor({'movie_attr_matrix':element_matrix,'movie_match_columns':movie_match_columns,\n",
    "#                        'movie_columns_match':movie_columns_match,'movie_match_row_movie':match_row_element,\n",
    "#                       'movie_match_movie_row':match_element_row,},bag_of_attr,is_censor = False)\n",
    "X = fe.fit_transform(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfe = ColdFeatureExtractor(fe)\n",
    "\n",
    "res_action = cfe.fit_transform(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_action.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(fe.train_movie_match_movie_row),len(fe.match_user_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_user = res_action['train_user']\n",
    "X_movie = res_action['train_movie']\n",
    "X_user.shape,X_movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_lightfm(train,item_features=None,seed = 0)\n",
    "seed = 0\n",
    "epochs = 30\n",
    "num_threads=4\n",
    "\n",
    "model = lightfm.LightFM(loss = 'warp',random_state=seed)\n",
    "\n",
    "\n",
    "# model.fit(train_matrix,user_features = train_user,item_features = element_matrix,epochs = epochs,num_threads = num_threads,\n",
    "#          verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "%time model.fit(X,epochs = epochs,num_threads = num_threads,verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "a,b = X.nonzero()\n",
    "D = defaultdict(set)\n",
    "for i,ii in tqdm.tqdm(zip(a,b),total = len(a)):\n",
    "    D[i].add(ii)\n",
    "# D = pd.DataFrame([a,b],index = ['row','columns']).T\n",
    "# D = D.groupby('row').agg(lambda x:frozenset(x.values))\n",
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fe.train_movie_match_row_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('sparsity',X.nnz/(X.shape[0]*X.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( set(test_users) - set(fe.match_user_row.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours import TFIDFRecommender,CosineRecommender,NearestNeighboursScorer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для implicit  надо фильмы*юзеры матрицу.\n",
    "# model = CosineRecommender()\n",
    "# model.fit(X.T.tocsr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CosineRecommender()\n",
    "model.fit(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_recomend(model,X,fe,test_users,D,mode = 'implicit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сделаем какой-нибудь сабмит из lightfm\n",
    "result = {}\n",
    "mode = 'lightfm'#'implicit'#'lightfm'\n",
    "cnt = 0\n",
    "for user_uid in tqdm.tqdm(test_users):\n",
    "    \n",
    "    # transform user_uid to model's internal user category\n",
    "    try:\n",
    "        user_cat = fe.match_user_row[user_uid]\n",
    "    except LookupError:\n",
    "        continue\n",
    "    if mode == 'lightfm':\n",
    "        need_cols = np.array(list(set(np.arange(X.shape[1])) - D.get(user_cat, set())))\n",
    "        recs = model.predict(user_cat,need_cols,num_threads=num_threads)\n",
    "        need_movies = np.argsort(-recs)[:20]\n",
    "        result[user_uid] = [int(fe.train_movie_match_row_movie[i]) for i in need_movies]\n",
    "    # переводим в фильмы\n",
    "    \n",
    "    # perform inference\n",
    "    if mode == 'implicit':\n",
    "        if cnt == 0:\n",
    "            ratings_matrix_T = X.tocsr()\n",
    "        recs = model.recommend(\n",
    "            user_cat,\n",
    "            X.tocsr(),\n",
    "            N=20,\n",
    "            filter_already_liked_items=True,\n",
    "            filter_items=D.get(user_uid, set())\n",
    "        )\n",
    "        result[user_uid] = [int(fe.train_movie_match_row_movie[i]) for i, _ in recs]\n",
    "        # drop scores and transform model's internal elelemnt category to element_uid for every prediction\n",
    "    # also convert np.uint64 to int so it could be json serialized later\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fe.train_movie_match_row_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(need_cols),len(recs),type(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('answer.json', 'w') as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import auc_score,precision_at_k\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = precision_at_k(model, te ,tr, k = 20,num_threads=4).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_old_tr_te_2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = new_old_tr_te_2['train_interactions']\n",
    "te = new_old_tr_te_2['test_interactions']\n",
    "uf = new_old_tr_te_2['user_features_train']\n",
    "tf = new_old_tr_te_2['user_features_test']\n",
    "print(tr.shape,te.shape,uf.shape,tf.shape)\n",
    "# tr[(tr < 3) &  (tr>0)] = -1\n",
    "# tr[(tr > 3)] = 1\n",
    "# te[(tr < 3) &  (te>0)] = -1\n",
    "# te[(tr > 3)] = 1\n",
    "\n",
    "model.fit(train_matrix,user_features=uf,epochs = epochs,num_threads =num_threads,\n",
    "         verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(0,np.arange(tr.shape[1]),user_features=tf[0,:],num_threads=num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict(0,np.arange(train_matrix.shape[1]),user_features=test_user[0,:],num_threads=num_threads)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import auc_score,precision_at_k\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = precision_at_k(model, train_matrix,user_features = train_user,item_features = element_matrix ,num_threads=num_threads).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.user_feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(test_users_dict,test):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
