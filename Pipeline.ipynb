{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import implicit\n",
    "import lightfm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',100)\n",
    "\n",
    "DATA_PATH = '../okko/orig_data'\n",
    "PREPARED_PATH = './prepared_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = pd.read_pickle(PREPARED_PATH+'actions_one_table.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.sort_index(inplace = True) # На всякий случай, иначе деление не будет работать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>consumption_mode</th>\n",
       "      <th>device_manufacturer</th>\n",
       "      <th>device_type</th>\n",
       "      <th>rating</th>\n",
       "      <th>watched_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_uid</th>\n",
       "      <th>element_uid</th>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>51</th>\n",
       "      <th>4.416546e+07</th>\n",
       "      <td>watch</td>\n",
       "      <td>S</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12382.0</td>\n",
       "      <td>3600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <th>4.375829e+07</th>\n",
       "      <td>watch</td>\n",
       "      <td>S</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5653.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <th>4.371904e+07</th>\n",
       "      <td>watch</td>\n",
       "      <td>S</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2646.0</td>\n",
       "      <td>5400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <th>4.377814e+07</th>\n",
       "      <td>watch</td>\n",
       "      <td>S</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6971.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <th>4.338109e+07</th>\n",
       "      <td>watch</td>\n",
       "      <td>S</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5894.0</td>\n",
       "      <td>6600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  action consumption_mode  \\\n",
       "user_uid element_uid ts                                     \n",
       "0        51          4.416546e+07  watch                S   \n",
       "         72          4.375829e+07  watch                S   \n",
       "         207         4.371904e+07  watch                S   \n",
       "         209         4.377814e+07  watch                S   \n",
       "         434         4.338109e+07  watch                S   \n",
       "\n",
       "                                   device_manufacturer  device_type  rating  \\\n",
       "user_uid element_uid ts                                                       \n",
       "0        51          4.416546e+07                 99.0          0.0     NaN   \n",
       "         72          4.375829e+07                 99.0          0.0     NaN   \n",
       "         207         4.371904e+07                 99.0          0.0     NaN   \n",
       "         209         4.377814e+07                 99.0          0.0     NaN   \n",
       "         434         4.338109e+07                 99.0          0.0     NaN   \n",
       "\n",
       "                                   watched_time  duration  type  \n",
       "user_uid element_uid ts                                          \n",
       "0        51          4.416546e+07       12382.0      3600     1  \n",
       "         72          4.375829e+07        5653.0      6000     1  \n",
       "         207         4.371904e+07        2646.0      5400     1  \n",
       "         209         4.377814e+07        6971.0      7200     1  \n",
       "         434         4.338109e+07        5894.0      6600     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(actions,mode = 'by_time',perc = (0.6,0.2,0.2)):\n",
    "    '''\n",
    "    здесь не очень аккуратно обращаемся с временем просмотра, потому что фильмы на границе должны быть \n",
    "    с обрезанной длительностью - но насрать\n",
    "    '''\n",
    "    X = actions.copy()\n",
    "    if mode == 'by_time':\n",
    "        X['ones'] = 1\n",
    "        X['increment'] = np.arange(len(X))\n",
    "        by_time = X.groupby(level = 2)['ones'].sum()\n",
    "        by_time.sort_index(inplace = True)\n",
    "        #проверили, что вроде как все ок и равномерно во времени\n",
    "        cur = 0\n",
    "        idx = []\n",
    "        for i in range(len(perc)):\n",
    "#             print(np.round((cur)*len(by_time)),np.round((cur+perc[i])*len(by_time)))\n",
    "            by_time_temp = by_time.iloc[int(np.round((cur)*len(by_time))):int(np.round((cur+perc[i])*len(by_time)))].index.values\n",
    "            print(len(by_time_temp))\n",
    "            mn = by_time_temp.min()\n",
    "            mx = by_time_temp.max()\n",
    "            cur+=perc[i]\n",
    "            idx.append(X.loc[(slice(None),slice(None),slice(mn,mx)),'increment'].values)\n",
    "            \n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6558458\n",
      "2186152\n",
      "2186153\n"
     ]
    }
   ],
   "source": [
    "idx = get_train_test(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43362401.96226887"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.iloc[idx[0]].index.get_level_values(2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43362401.97085199"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.iloc[idx[1]].index.get_level_values(2).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43828341.47903843"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.iloc[idx[1]].index.get_level_values(2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43828341.48519237"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.iloc[idx[2]].index.get_level_values(2).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    8296227\n",
       "P     873834\n",
       "R     472951\n",
       "Name: consumption_mode, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.consumption_mode.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>consumption_mode</th>\n",
       "      <th>device_manufacturer</th>\n",
       "      <th>device_type</th>\n",
       "      <th>rating</th>\n",
       "      <th>watched_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_uid</th>\n",
       "      <th>element_uid</th>\n",
       "      <th>ts</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>51</th>\n",
       "      <th>4.416546e+07</th>\n",
       "      <td>watch</td>\n",
       "      <td>S</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12382.0</td>\n",
       "      <td>3600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <th>4.375829e+07</th>\n",
       "      <td>watch</td>\n",
       "      <td>S</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5653.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <th>4.371904e+07</th>\n",
       "      <td>watch</td>\n",
       "      <td>S</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2646.0</td>\n",
       "      <td>5400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <th>4.377814e+07</th>\n",
       "      <td>watch</td>\n",
       "      <td>S</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6971.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <th>4.338109e+07</th>\n",
       "      <td>watch</td>\n",
       "      <td>S</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5894.0</td>\n",
       "      <td>6600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  action consumption_mode  \\\n",
       "user_uid element_uid ts                                     \n",
       "0        51          4.416546e+07  watch                S   \n",
       "         72          4.375829e+07  watch                S   \n",
       "         207         4.371904e+07  watch                S   \n",
       "         209         4.377814e+07  watch                S   \n",
       "         434         4.338109e+07  watch                S   \n",
       "\n",
       "                                   device_manufacturer  device_type  rating  \\\n",
       "user_uid element_uid ts                                                       \n",
       "0        51          4.416546e+07                 99.0          0.0     NaN   \n",
       "         72          4.375829e+07                 99.0          0.0     NaN   \n",
       "         207         4.371904e+07                 99.0          0.0     NaN   \n",
       "         209         4.377814e+07                 99.0          0.0     NaN   \n",
       "         434         4.338109e+07                 99.0          0.0     NaN   \n",
       "\n",
       "                                   watched_time  duration  type  \n",
       "user_uid element_uid ts                                          \n",
       "0        51          4.416546e+07       12382.0      3600     1  \n",
       "         72          4.375829e+07        5653.0      6000     1  \n",
       "         207         4.371904e+07        2646.0      5400     1  \n",
       "         209         4.377814e+07        6971.0      7200     1  \n",
       "         434         4.338109e+07        5894.0      6600     1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вроде не пересекается.\n",
    "train,test,valid = actions.iloc[idx[0]],actions.iloc[idx[1]],actions.iloc[idx[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(actions):\n",
    "    '''\n",
    "    Функция, которая вернет число просмотреннх серий каждым пользователем каждого сериала, потом вернет то,что недопотребил\n",
    "    А потом то, что точно потребил согласно правилам соревнования - например, так можно вычислить примерную длительность сериала \n",
    "    и его же рекомендовать в потребленные после.\n",
    "    '''\n",
    "    watch_actions = actions[actions.action == 'watch']\n",
    "    # Блок нахождения всяких статистик по сериалам\n",
    "    serials = watch_actions[watch_actions['type'] != 1]\n",
    "    # Заменим длиетльность на 0, там где длительности нет.. или это очень короткие, надо подумоть.\n",
    "    serials['num_of_series'] = (serials['watched_time']/serials['duration']).fillna(0).replace(np.inf,0).astype(int)\n",
    "    serials['time_being'] = serials.index.get_level_values(2)\n",
    "    dur_being = serials.groupby(level = 1).agg({'time_being':[min,len],'num_of_series':[lambda x:x.mode()[0],max]})\n",
    "    dur_being.columns = ['time_being','count_of_watch','num_of_series_mode','num_of_series_max']\n",
    "    # Модифицируем длитеьность сериала - как произвелдение числа серий на продолжиттельность одной\n",
    "    dur = watch_actions.join(dur_being['num_of_series_max'])['num_of_series_max']*watch_actions['duration']\n",
    "    watch_actions.loc[~dur.isnull(),'duration'] = dur[~dur.isnull()]\n",
    "    \n",
    "    \n",
    "    # Блок нахождения статистик по фильмам для пользователя\n",
    "    films = watch_actions[watch_actions['type'] == 1]\n",
    "    # Здесь важно видимо, как долго смотрел\n",
    "    films['time_being'] = films.index.get_level_values(2)\n",
    "    dur_films = films.groupby(level = 1).agg({'time_being':[min,len]})\n",
    "    dur_films.columns = ['time_being','count_of_watch']\n",
    "    \n",
    "    # Блок нахождения статистик по фильмам и пользователям\n",
    "    watch_actions['rel_dur'] = (watch_actions['watched_time']/watch_actions['duration'])\n",
    "    target = 1*(watch_actions['rel_dur'] >= 1/3) | watch_actions['consumption_mode'].isin(['R','P']) \n",
    "    target = target.groupby(level = [0,1]).mean()\n",
    "    watch_actions = watch_actions.groupby(level = [0,1]).mean()\n",
    "    watch_actions['rel_dur'] = watch_actions['rel_dur'].replace(np.inf,1)# Заглушка для фильмов с 0 длительностью\n",
    "    \n",
    "    \n",
    "    \n",
    "    return dur_being,dur_films,watch_actions,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%time \n",
    "dur_being_train,dur_films_train,watch_actions_train,target_train = get_target(train)\n",
    "dur_being_test,dur_films_test,watch_actions_test,target_test = get_target(test)\n",
    "dur_being_valid,dur_films_valid,watch_actions_valid,target_valid = get_target(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#watch_actions_train.loc[watch_actions_train['type']!=1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получили фичи для фильмов\n",
    "import pickle\n",
    "with open(PREPARED_PATH+'catalogue_features.pkl','rb') as f:\n",
    "    match_element_row,match_row_element,match_columns,element_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from scipy.sparse import coo_matrix,vstack,hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "with open(PREPARED_PATH+'bag_of_attr_movie.pkl','rb') as f:\n",
    "    bag_of_attr = pickle.load(f)\n",
    "\n",
    "\n",
    "class FeatureExtractor(TransformerMixin):\n",
    "    def __init__(self,all_about_movie,bag_of_attr,is_censor = True,delimiter = 4, mode = 'raiting',target_col_name = 'rating'):\n",
    "        self.all_about_movie = all_about_movie\n",
    "        self.movie_attr_matrix = all_about_movie['movie_attr_matrix']\n",
    "        self.movie_match_columns_attr = all_about_movie['movie_match_columns']\n",
    "        self.movie_match_attr_columns = all_about_movie['movie_match_columns']\n",
    "        self.movie_match_row_movie = all_about_movie['movie_match_row_movie']\n",
    "        self.movie_match_movie_row = all_about_movie['movie_match_movie_row']\n",
    "\n",
    "        self.is_censor = is_censor\n",
    "        self.delimiter = delimiter\n",
    "        self.mode = mode\n",
    "    def fit(self,X):\n",
    "        watch_actions_train = X[X['action'] == 'watch']\n",
    "        # Сначала нам нужна матрица из всех просмотренных фильмов в трейне и меппинги оттуда \n",
    "        # - это исчерпывающая информация известная на конец трейна\n",
    "        res = get_users_features(watch_actions_train,bag_of_attr)\n",
    "        \n",
    "        self.match_user_row = res[0] \n",
    "        self.match_row_user = res[1]\n",
    "        self.match_feature_columns = res[2]\n",
    "        self.match_columns_feature = res[3]\n",
    "        self.train_user = res[4]\n",
    "        # Вообще фильмов здесь намного больше дб, наверное стоит как-то смеппить признак 1\n",
    "        # но для обычных рекомендаций это не так уж и важно.\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return self\n",
    "    def transform(self,X,y = None,):\n",
    "        if mode == 'rating':\n",
    "            part_of_train = X.loc[X.action =='rate',target_col_name].groupby(level = [0,1]).mean().to_frame() \n",
    "        elif mode == 'duration':\n",
    "            part_of_train = X.loc[X.action =='watch',target_col_name].groupby(level = [0,1]).mean().to_frame()\n",
    "        res = df_to_matrix(part_of_train,self.match_user_row,self.match_element_row,self.delimiter)\n",
    "        return res\n",
    "class ColdFeatureExtractor(TransformerMixin):\n",
    "    def __init__(self,fitted_FE):\n",
    "        self.fitted_FE = fitted_FE\n",
    "        self.im_columns = ['is_purchase',\n",
    "             'is_rent',\n",
    "             'is_subscription',\n",
    "             'duration',\n",
    "             'feature_1',\n",
    "             'feature_2',\n",
    "             'feature_3',\n",
    "             'feature_4',\n",
    "             'feature_5',\n",
    "             'type_movie',\n",
    "             'type_serial',]\n",
    "        \n",
    "    def fit(self,X):\n",
    "        # Задача вычленить фильмы из трейна из большой матрицы фильмов и перенумеровать id\n",
    "        # Здесь же когда-нибудь появтся новинки\n",
    "        self.movie_train = np.unique(X[X['action'] == 'watch'].index.get_level_values(1))\n",
    "        \n",
    "        # Теперь нужна матрица атрибутов фильмов для юзера\n",
    "        self.attr_train_map = list(self.fitted_FE.match_feature_columns.keys())\n",
    "        \n",
    "        self.train_movie_rows = [self.fitted_FE.movie_match_movie_row[i] for i in self.movie_train]\n",
    "        self.train_movie_cols = [self.fitted_FE.movie_match_attr_columns[i] for i in  self.attr_train_map]\n",
    "        \n",
    "        \n",
    "        \n",
    "        return self\n",
    "    def transform(self,X,y = None,):\n",
    "        # Сначала надо получить список не новинок, доступных на конец трейна\n",
    "        res = get_cold_start_matrix(actions,match_user_row,match_feature_columns,match_movie_columns):\n",
    "        \n",
    "        # Теперь набор атрибутов и \n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получили фичи для юзеров (пока какие-то)\n",
    "# import pickle\n",
    "# with open(PREPARED_PATH+'catalogue_users.pkl','rb') as f:\n",
    "#     match_element_row_user,match_row_element_user,match_columns_user,element_matrix_user = pickle.load(f)\n",
    "# Кажется, что их правильно пересчитывать по тем, кто есть во времени сейчас. \n",
    "\n",
    "# Итак, нам надо вопроизвести максимально похоже условия использования системы. т.е. на момент времени t_train_end\n",
    "# мы имеем только фильмы из трейна. и атрибуты от фильмов из трейна.\n",
    "# теперь в момент t_test_end  мы будем иметь N  новых фильмов и M  новых пользователей - это задачи холодного старта.\n",
    "# Разобьем нашу задачу на 4 и правильно сформируем тест.\n",
    "# 1- старые пользователи - старые фильмы\n",
    "# 2 - новые пользователи - старые фильмы\n",
    "# 3 - старые пользователи - новые фильмы\n",
    "# 4 - новые пользователи - новые фильмы\n",
    "\n",
    "\n",
    "def get_users_features(actions,bag_of_attr):\n",
    "    '''\n",
    "    Получаем трейн\n",
    "    bag_of_attr - словарь, где просто каждому id  фильма сопоставлена строка атрибутов через запятую.\n",
    "    строго  говоря в просмотренных фильмах атрибутов может оказаться меньше, чем во всем пуле фильмов, но я \n",
    "    пока не знаю проблема ли это ToDo\n",
    "    Если history_movie определен из теста, например, то мы должны убирать новинки из формирования матрицы для простого обучения.\n",
    "    Без холодного старта.\n",
    "    '''\n",
    "    # Приделаем каждому чуваку атрибуты просмотренных фильмов. ну или вообще по всем действиям - они все позитивные\n",
    "    ind_user = []\n",
    "    buf = []\n",
    "    for i in tqdm.tqdm(np.unique(actions.index.get_level_values(0))):\n",
    "        \n",
    "        temp = np.unique(actions.loc[i].index.get_level_values(0))\n",
    "        ind_user.append(i)\n",
    "\n",
    "        s = ''\n",
    "        for ii in temp:\n",
    "#             if (history_movie is None) or (ii in list(history_movie.keys())):\n",
    "                s+=bag_of_attr[ii]\n",
    "\n",
    "                s+=','\n",
    "        #assert X.shape[1] == len(a)\n",
    "        buf.append(s)\n",
    "\n",
    "    cv1 = CountVectorizer(token_pattern='\\d+',)\n",
    "    X_user = cv1.fit_transform(buf)\n",
    "    \n",
    "    match_user_row = {i:ii for ii,i in enumerate(ind_user)}\n",
    "    match_row_user = {ii:i for ii,i in enumerate(ind_user)}\n",
    "    match_feature_columns = {i:ii for ii,i in enumerate(list(cv1.get_feature_names()))}\n",
    "    match_columns_feature = {ii:i for ii,i in enumerate(list(cv1.get_feature_names()))}\n",
    "    print(X_user.shape,len(match_user_row),len(match_feature_columns))\n",
    "    return match_user_row,match_row_user,match_feature_columns,match_columns_feature,X_user\n",
    "def shape_corrector(X,num_col,num_row):\n",
    "    if X.shape[0]<num_row:\n",
    "        X = vstack((X,coo_matrix((int(num_row - X.shape[0]),X.shape[1]))))\n",
    "    if X.shape[1]<num_col:\n",
    "        \n",
    "        X = hstack((X,coo_matrix((X.shape[0],int(num_col - X.shape[1])))))\n",
    "    return X\n",
    "def get_cold_start_matrix(actions,match_user_row,match_feature_columns,match_movie_columns):\n",
    "    '''\n",
    "    Нужно переписать через coo_matrix, чтоб все атрибуты совпадали\n",
    "    '''\n",
    "    # Наполнение по тесту для старых пользователей и старых фильмов\n",
    "    row_ = []\n",
    "    col_ = []\n",
    "    ones = []\n",
    "    # Наполнение матрицы по старым атрибутам для новых пользователей\n",
    "    row_user = []\n",
    "    col_user = []\n",
    "    ones_user = []\n",
    "    # Здесь id  фильмов, которые не смотрели в трейне\n",
    "    new_movie_buf = []\n",
    "    \n",
    "    buf = []\n",
    "    \n",
    "    ind_user = []\n",
    "    for i in tqdm.tqdm(np.unique(actions.index.get_level_values(0))):\n",
    "        if i in match_user_row:\n",
    "            temp = np.unique(actions.loc[i].index.get_level_values(0))\n",
    "\n",
    "\n",
    "            s = ''\n",
    "            for ii in temp:\n",
    "                for k in bag_of_attr[ii].split(','):\n",
    "                    if k in match_feature_columns:\n",
    "                        row_.append(match_user_row[i])\n",
    "                        col_.append(match_feature_columns[k])\n",
    "                        ones.append(1)\n",
    "                if ii not in match_movie_columns:\n",
    "                    # Фильма нет в трейне\n",
    "                    # Значит нужно просто сохранить его id и забрать из большой таблицы с фичами и атрибутами\n",
    "                    new_movie_buf.append(ii)\n",
    "                    \n",
    "        else:\n",
    "            # Пользователя не было в трейне\n",
    "            # По сути надо создать еще несколько массивов и мапов\n",
    "            temp = np.unique(actions.loc[i].index.get_level_values(0))\n",
    "            ind_user.append(i)\n",
    "\n",
    "            for ii in temp:\n",
    "                for k in bag_of_attr[ii].split(','):\n",
    "                    if k in match_feature_columns:\n",
    "                        row_user.append(len(ind_user)-1)\n",
    "                        col_user.append(match_feature_columns[k])\n",
    "                        ones_user.append(1)\n",
    "                if ii not in match_movie_columns:\n",
    "                    # Фильма нет в трейне и еще нет пользователя\n",
    "                    pass\n",
    "                    # ХЗ че с этим делать\n",
    "            \n",
    "\n",
    "    # По построению test matrix должна иметь те же размеры, что и трейн матрикс, но тут надо быть аккуратнее\n",
    "    # Вроде как если не попадется максимальный номер строки или столбца, то он его не нарастит - надо проверку бы\n",
    "    test_matrix = coo_matrix((ones,(row_,col_)))# Старые юзеры, старые фильмы, но новое распределение атрибутов\n",
    "    test_matrix = shape_corrector(test_matrix,max(match_feature_columns.values())+1,max(match_user_row.values())+1)\n",
    "    # ToDo - мб нужно будет как-то сложить матрицу атрибутов, но вроде не надо\n",
    "    \n",
    "    \n",
    "    new_user_matrix = coo_matrix((ones_user,(row_user,col_user)))\n",
    "    new_match_user_row = {i:ii for ii,i in enumerate(ind_user)}\n",
    "    new_match_row_user = {ii:i for ii,i in enumerate(ind_user)}\n",
    "    new_user_matrix = shape_corrector(new_user_matrix,max(match_feature_columns.values())+1,max(new_match_user_row.values())+1)\n",
    "    \n",
    "    \n",
    "    new_match_row_movie = {ii:i for ii,i in enumerate(new_movie_buf)}\n",
    "    new_match_movie_row = {i:ii for ii,i in enumerate(new_movie_buf)}\n",
    "    \n",
    "    \n",
    "    return test_matrix,new_match_user_row,new_match_row_user,new_user_matrix,new_match_row_movie,new_match_movie_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_to_matrix(X,match_user_row,match_element_row, is_censor = True, delimiter = 4):\n",
    "    '''\n",
    "    На вход подается датафрейм с мультииндексом <user_id, element_id> и некоторой оценкой пары, затем он переупорядочивается и дополняется \n",
    "    по шаблонам из строк всяких спарс матричек для фильмов и юзеров\n",
    "    match_user_row - отображение из айди в номер строки в матрице, match_element_row - аналогично\n",
    "    '''\n",
    "    Y = X.copy()\n",
    "    if is_censor:\n",
    "        Y[(Y<delimiter)] = -1\n",
    "        Y[(Y>=delimiter)] = 1\n",
    "    Y['users'] = Y.index.get_level_values(0).map(match_user_row)\n",
    "    Y['items'] = Y.index.get_level_values(1).map(match_element_row)\n",
    "    Y.dropna(subset = ['users','items'],inplace = True)\n",
    "    Y['users'] = Y['users'].astype(int)\n",
    "    Y['items'] = Y['items'].astype(int)\n",
    "    Z = coo_matrix((Y[X.columns].values.squeeze(),(Y['users'].values,Y['items'].values)))\n",
    "    print(max(match_element_row.values())+1,max(match_user_row.values())+1)\n",
    "    Z = shape_corrector(Z,max(match_element_row.values())+1,max(match_user_row.values()) +1)\n",
    "    print(X.shape,Y.shape)\n",
    "    print(Z.shape)\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Получим что-то сначала для трейна, причем для рейтингового\n",
    "# Вообще парллелится, но пока непонятно зачем кроме тренировки\n",
    "# Через рейтинги \n",
    "# match_user_row,match_row_user,match_feature_columns,match_columns_feature,train_user = get_users_features(train[train.action =='rate'],bag_of_attr)\n",
    "\n",
    "# X = train.loc[train.action =='rate','rating'].groupby(level = [0,1]).mean().to_frame()\n",
    "# Через длительность просмотра\n",
    "match_user_row,match_row_user,match_feature_columns,match_columns_feature,train_user = get_users_features(watch_actions_train,bag_of_attr)\n",
    "\n",
    "X = watch_actions_train['rel_dur'].groupby(level = [0,1]).mean().to_frame().replace(np.inf,1).fillna(0)\n",
    "# X.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = df_to_matrix(X,match_user_row,match_element_row,delimiter=1/3)\n",
    "# test_matrix = df_to_matrix(test.loc[test.action =='rate','rating'].groupby(level = [0,1]).mean().to_frame(),match_user_row,match_element_row)\n",
    "XX = watch_actions_test['rel_dur'].groupby(level = [0,1]).mean().to_frame().replace(np.inf,1).fillna(0)\n",
    "test_matrix = df_to_matrix(XX,match_user_row,match_element_row,delimiter=1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user_matrix,new_match_user_row,new_match_row_user,new_user_matrix,new_match_row_movie,new_match_movie_row = get_cold_start_matrix(watch_actions_test,match_user_row,match_feature_columns,match_element_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_matrix.shape,len(new_match_user_row),len(new_match_row_user),new_user_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь большая простынь с переименованием данных\n",
    "#  Под каждую из 3 задач\n",
    "# 1 стврые - старые\n",
    "old_old_tr_te_1 = {'train_interactions':train_matrix,\n",
    "                 'test_interactions':test_matrix,\n",
    "                'user_features_train':None,\n",
    "                'item_features_train':None,\n",
    "                'user_features_test':None,\n",
    "                'item_features_test':None,}\n",
    "# 2\n",
    "new_old_tr_te_2 = {'train_interactions':train_matrix,\n",
    "                 'test_interactions':test_matrix,\n",
    "                'user_features_train':train_user,\n",
    "                'item_features_train':None,\n",
    "                'user_features_test':new_user_matrix,\n",
    "                'item_features_test':None,}\n",
    "# 3\n",
    "\n",
    "# Сначала надо обрезать фильмы по атрибутам, которые известны только по трейну.\n",
    "need_columns = ['is_purchase',\n",
    " 'is_rent',\n",
    " 'is_subscription',\n",
    " 'duration',\n",
    " 'feature_1',\n",
    " 'feature_2',\n",
    " 'feature_3',\n",
    " 'feature_4',\n",
    " 'feature_5',\n",
    " 'type_movie',\n",
    " 'type_serial',]\n",
    "need_columns.extend(list(match_feature_columns.keys()))\n",
    "need_columns =[match_columns.index(i) for i in need_columns]\n",
    "\n",
    "# Теперь нужны новинки из теста, и их надо достать из большой матрицы с филмами\n",
    "# ToDo - там еще по идее должны переделываться match rows для всех не новинок, но я пока забью.\n",
    "\n",
    "\n",
    "\n",
    "# element_matrix\n",
    "# old_new_tr_te_3 = {'train_interactions':train_matrix,\n",
    "#                  'test_interactions':test_matrix,\n",
    "#                 'user_features_train':None,\n",
    "#                 'item_features_train':None,\n",
    "#                 'user_features_test':None,\n",
    "#                 'item_features_test':None,}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(match_user_row),len(match_element_row),train_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_lightfm(train,item_features=None,seed = 0)\n",
    "seed = 0\n",
    "epochs = 30\n",
    "num_threads=4\n",
    "\n",
    "model = lightfm.LightFM(loss = 'warp',random_state=seed)\n",
    "\n",
    "\n",
    "# model.fit(train_matrix,user_features = train_user,item_features = element_matrix,epochs = epochs,num_threads = num_threads,\n",
    "#          verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = old_old_tr_te_1['train_interactions']\n",
    "te = old_old_tr_te_1['test_interactions']\n",
    "# tr[(tr < 3) &  (tr>0)] = -1\n",
    "# tr[(tr > 3)] = 1\n",
    "# te[(tr < 3) &  (te>0)] = -1\n",
    "# te[(tr > 3)] = 1\n",
    "\n",
    "model.fit(train_matrix,epochs = epochs,num_threads = num_threads,\n",
    "         verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import auc_score,precision_at_k\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = precision_at_k(model, te ,tr, k = 20,num_threads=4).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_old_tr_te_2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = new_old_tr_te_2['train_interactions']\n",
    "te = new_old_tr_te_2['test_interactions']\n",
    "uf = new_old_tr_te_2['user_features_train']\n",
    "tf = new_old_tr_te_2['user_features_test']\n",
    "print(tr.shape,te.shape,uf.shape,tf.shape)\n",
    "# tr[(tr < 3) &  (tr>0)] = -1\n",
    "# tr[(tr > 3)] = 1\n",
    "# te[(tr < 3) &  (te>0)] = -1\n",
    "# te[(tr > 3)] = 1\n",
    "\n",
    "model.fit(train_matrix,user_features=uf,epochs = epochs,num_threads =num_threads,\n",
    "         verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "tf = csr_matrix(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(0,np.arange(tr.shape[1]),user_features=tf[0,:],num_threads=num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict(0,np.arange(train_matrix.shape[1]),user_features=test_user[0,:],num_threads=num_threads)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import auc_score,precision_at_k\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = precision_at_k(model, train_matrix,user_features = train_user,item_features = element_matrix ,num_threads=num_threads).mean()\n",
    "print('Collaborative filtering train AUC: %s' % train_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.user_feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(test_users_dict,test):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
